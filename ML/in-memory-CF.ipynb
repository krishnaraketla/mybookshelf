{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In memory collaboarative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### works better with full interactions. (Unread book ratings included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the CSV files\n",
    "book_id_map_df = pd.read_csv(\"./data/book_id_map.csv\")\n",
    "book_works_df = pd.read_csv(\"./data/book_works.csv\")\n",
    "\n",
    "book_id_map = dict(zip(book_id_map_df['book_id_csv'], book_id_map_df['book_id']))\n",
    "\n",
    "def get_work_id(book_id):\n",
    "    return book_id_map[book_id]\n",
    "\n",
    "# Define the function to get original title by work_id\n",
    "def get_original_title_by_book_id(work_id, book_works_df):\n",
    "    # Find the row with the matching best_book_id\n",
    "    match = book_works_df[book_works_df['best_book_id'] == work_id]\n",
    "    \n",
    "    # If a match is found, return the original title\n",
    "    if not match.empty:\n",
    "        return match['original_title'].values[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User - User CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def normalize_ratings(user_item_matrix):\n",
    "    user_means = user_item_matrix.mean(axis=1).values.reshape(-1, 1)\n",
    "    user_stds = user_item_matrix.std(axis=1).replace(0, 1).values.reshape(-1, 1)  # Replace 0 std with 1 to avoid division by zero\n",
    "    normalized_matrix = (user_item_matrix - user_means) / user_stds\n",
    "    return normalized_matrix, user_means, user_stds\n",
    "\n",
    "def predict_ratings(user_item_matrix, user_similarity_df, user_means, user_stds):\n",
    "    ratings_diff = user_item_matrix\n",
    "    pred = user_means + user_similarity_df.dot(ratings_diff) / np.array([np.abs(user_similarity_df).sum(axis=1)]).T\n",
    "    pred = pred * user_stds  # Scale predictions back to original scale\n",
    "    return pred\n",
    "\n",
    "def get_user_based_recommendations(interactions, new_user_ratings, n=10):\n",
    "    \"\"\"\n",
    "    Generate user-based collaborative filtering recommendations for a new user.\n",
    "\n",
    "    Parameters:\n",
    "    - interactions (pd.DataFrame): Existing user-item interactions DataFrame.\n",
    "    - new_user_ratings (pd.DataFrame): New user's ratings DataFrame with columns ['user_id', 'book_id', 'rating'].\n",
    "    - n (int): Number of recommendations to generate.\n",
    "\n",
    "    Returns:\n",
    "    - list: Top-N recommended book IDs for the new user.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_top_n_recommendations(predicted_ratings_df, user_id, n=10):\n",
    "        user_pred_ratings = predicted_ratings_df.loc[user_id]\n",
    "        user_pred_ratings_sorted = user_pred_ratings.sort_values(ascending=False)\n",
    "        top_n_books = user_pred_ratings_sorted.index[:n]\n",
    "        top_n_scores = user_pred_ratings_sorted.values[:n]\n",
    "        return top_n_books, top_n_scores\n",
    "\n",
    "    # Append the new user's ratings to the interactions DataFrame\n",
    "    updated_interactions = pd.concat([interactions, new_user_ratings], ignore_index=True)\n",
    "\n",
    "    # Create the updated user-item interaction matrix\n",
    "    updated_user_item_matrix = updated_interactions.pivot(index='user_id', columns='book_id', values='rating')\n",
    "    updated_user_item_matrix.fillna(0, inplace=True)\n",
    "    \n",
    "    # Normalize the ratings\n",
    "    normalized_matrix, user_means, user_stds = normalize_ratings(updated_user_item_matrix)\n",
    "\n",
    "    # Check for NaN or infinity values and handle them\n",
    "    normalized_matrix = np.nan_to_num(normalized_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Compute the user similarity matrix using Pearson correlation\n",
    "    user_similarity = cosine_similarity(normalized_matrix)\n",
    "    user_similarity_df = pd.DataFrame(user_similarity, index=updated_user_item_matrix.index, columns=updated_user_item_matrix.index)\n",
    "    \n",
    "    # Predict ratings for the updated user-item matrix\n",
    "    predicted_ratings = predict_ratings(normalized_matrix, user_similarity_df, user_means, user_stds)\n",
    "    predicted_ratings_df = pd.DataFrame(predicted_ratings, index=updated_user_item_matrix.index, columns=updated_user_item_matrix.columns)\n",
    "    \n",
    "    # Get top-N recommendations for the new user\n",
    "    new_user_id = new_user_ratings['user_id'].iloc[0]\n",
    "    top_n_recommendations, top_n_scores = get_top_n_recommendations(predicted_ratings_df, new_user_id, n)\n",
    "\n",
    "    return top_n_recommendations.tolist(), top_n_scores.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New user's ratings DataFrame\n",
    "new_user_ratings = pd.DataFrame({\n",
    "    'user_id': 999999999,  # Replace with the new user's ID\n",
    "    'book_id': [7300, 1201, 100385, 530615, 48625, 14870, 7170, 19782, 1146577],\n",
    "    'rating': [5, 4, 3, 5, 1, 3, 2, 5, 1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bell Jar\n",
      "Little Women\n",
      "Cobalt Blue: The Novel\n",
      "The Sins of the Father\n",
      "Call Me by Your Name\n",
      "The Pact\n",
      "The Picture of Dorian Gray\n",
      "Sula\n",
      "Never Let Me Go\n"
     ]
    }
   ],
   "source": [
    "new_user_books = [7300, 1201, 100385, 530615, 48625, 14870, 7170, 19782, 1146577]\n",
    "\n",
    "for book_id in new_user_books:\n",
    "    work_id = get_work_id(book_id)\n",
    "    print(get_original_title_by_book_id(work_id, book_works_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 user-based recommendations for the new user: [7300, 19509, 19506, 1201, 14870, 19508, 7170, 19510, 19507, 7432, 1012, 1003, 1402, 1211, 786, 943, 670, 536, 1013, 1574, 862, 460, 1000, 613, 1007, 1386, 941, 839, 938, 1010]\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Existing interactions DataFrame\n",
    "interactions = pd.read_csv(\"./data/interactions.csv\")\n",
    "\n",
    "# Get user-based CF recommendations\n",
    "top_n_recommendations_user_based, top_n_scores_user_based = get_user_based_recommendations(interactions, new_user_ratings, n=30)\n",
    "print(f\"Top-10 user-based recommendations for the new user: {top_n_recommendations_user_based}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item - Item CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 item-based recommendations for the new user: [1146577, 530615, 100385, 48625, 19782, 14870, 7300, 7170, 1201, 13293, 13311, 13310, 13309, 13304, 13302, 13298, 13296, 13294, 13281, 13289, 13283, 13282, 13333, 13276, 13275, 13273, 13266, 13258, 13235, 6508]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_item_based_recommendations(interactions, new_user_ratings, n=10):\n",
    "    \"\"\"\n",
    "    Generate item-based collaborative filtering recommendations for a new user.\n",
    "\n",
    "    Parameters:\n",
    "    - interactions (pd.DataFrame): Existing user-item interactions DataFrame.\n",
    "    - new_user_ratings (pd.DataFrame): New user's ratings DataFrame with columns ['user_id', 'book_id', 'rating'].\n",
    "    - n (int): Number of recommendations to generate.\n",
    "\n",
    "    Returns:\n",
    "    - list: Top-N recommended book IDs for the new user.\n",
    "    \"\"\"\n",
    "\n",
    "    def predict_ratings_item_based(user_item_matrix, item_similarity_df):\n",
    "        mean_user_rating = user_item_matrix.mean(axis=1)\n",
    "        ratings_diff = user_item_matrix - mean_user_rating[:, np.newaxis]\n",
    "        sum_sim = np.array([np.abs(item_similarity_df).sum(axis=1)])\n",
    "        sum_sim[sum_sim == 0] = 1e-9  # To avoid division by zero\n",
    "        pred = mean_user_rating[:, np.newaxis] + ratings_diff.dot(item_similarity_df) / sum_sim\n",
    "        return pred\n",
    "\n",
    "    def get_top_n_recommendations(predicted_ratings_df, user_id, n=10):\n",
    "        user_pred_ratings = predicted_ratings_df.loc[user_id]\n",
    "        user_pred_ratings_sorted = user_pred_ratings.sort_values(ascending=False)\n",
    "        top_n_books = user_pred_ratings_sorted.index[:n]\n",
    "        return top_n_books\n",
    "\n",
    "    # Append the new user's ratings to the interactions DataFrame\n",
    "    updated_interactions = pd.concat([interactions, new_user_ratings], ignore_index=True)\n",
    "\n",
    "    # Create the updated user-item interaction matrix\n",
    "    updated_user_item_matrix = updated_interactions.pivot(index='user_id', columns='book_id', values='rating')\n",
    "    updated_user_item_matrix.fillna(0, inplace=True)\n",
    "\n",
    "    # Compute the updated item similarity matrix\n",
    "    updated_item_similarity = cosine_similarity(updated_user_item_matrix.T)\n",
    "    updated_item_similarity_df = pd.DataFrame(updated_item_similarity, index=updated_user_item_matrix.columns, columns=updated_user_item_matrix.columns)\n",
    "\n",
    "    # Predict ratings for the updated user-item matrix\n",
    "    updated_predicted_ratings_item_based = predict_ratings_item_based(updated_user_item_matrix.values, updated_item_similarity_df.values)\n",
    "    updated_predicted_ratings_item_based_df = pd.DataFrame(updated_predicted_ratings_item_based, index=updated_user_item_matrix.index, columns=updated_user_item_matrix.columns)\n",
    "\n",
    "    # Get top-N recommendations for the new user\n",
    "    new_user_id = new_user_ratings['user_id'].iloc[0]\n",
    "    top_n_recommendations = get_top_n_recommendations(updated_predicted_ratings_item_based_df, new_user_id, n)\n",
    "\n",
    "    return top_n_recommendations.tolist()\n",
    "\n",
    "# Example usage:\n",
    "# Existing interactions DataFrame\n",
    "interactions = pd.read_csv(\"./data/interactions.csv\")\n",
    "\n",
    "# Get item-based CF recommendations\n",
    "top_n_recommendations_item_based = get_item_based_recommendations(interactions, new_user_ratings, n=30)\n",
    "print(f\"Top-10 item-based recommendations for the new user: {top_n_recommendations_item_based}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bell Jar\n",
      "Little Women\n",
      "Cobalt Blue: The Novel\n",
      "The Sins of the Father\n",
      "Call Me by Your Name\n",
      "The Pact\n",
      "The Picture of Dorian Gray\n",
      "Sula\n",
      "Never Let Me Go\n"
     ]
    }
   ],
   "source": [
    "for book_id in new_user_books:\n",
    "    work_id = get_work_id(book_id)\n",
    "    print(get_original_title_by_book_id(work_id, book_works_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user-user collaborative filtering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bell Jar\n",
      "Breathing Underwater\n",
      "nan\n",
      "Little Women\n",
      "The Pact\n",
      "Snobs\n",
      "The Picture of Dorian Gray\n",
      "Dragon Spear\n",
      "Mark of the Thief\n",
      "Gone with the Wind (1 vol.)\n",
      "Pride and Prejudice\n",
      "The Book Thief\n",
      "Water for Elephants\n",
      "To Kill a Mockingbird\n",
      "Harry Potter and the Philosopher's Stone\n",
      "The Fellowship of the Ring\n",
      "The Hunger Games\n",
      "The Kite Runner\n",
      "The Giver\n",
      "The Catcher in the Rye\n",
      "The Secret Garden\n",
      "Twilight\n",
      "Harry Potter and the Deathly Hallows\n",
      "The Help\n",
      "Mockingjay\n",
      "Harry Potter and the Prisoner of Azkaban\n",
      "Lord of the Flies\n",
      "Harry Potter and the Goblet of Fire\n",
      "The Curious Incident of the Dog in the Night-Time\n"
     ]
    }
   ],
   "source": [
    "recommended_books = top_n_recommendations_user_based\n",
    "\n",
    "count = 0\n",
    "for book_id in recommended_books:\n",
    "    work_id = get_work_id(book_id)\n",
    "    title = get_original_title_by_book_id(work_id, book_works_df)\n",
    "    if title == None or title == \"nan\" :\n",
    "        count+=1\n",
    "        continue\n",
    "    print(title)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item-item collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Never Let Me Go\n",
      "The Sins of the Father\n",
      "Cobalt Blue: The Novel\n",
      "Call Me by Your Name\n",
      "Sula\n",
      "The Pact\n",
      "The Bell Jar\n",
      "The Picture of Dorian Gray\n",
      "Little Women\n",
      "nan\n",
      "Killing Jesus: A History\n",
      "The Mermaid's Sister\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angel Time\n",
      "My Sunshine Away\n",
      "Of Love and Evil\n",
      "The Girl from Krakow\n",
      "Thor, Volume 2: Who Holds the Hammer?\n",
      "nan\n",
      "Pines\n",
      "Thor, Volume 1: The Goddess of Thunder\n",
      "The Awakening\n",
      "Dear Ijeawele, Or a Feminist Manifesto in Fifteen Suggestions\n",
      "nan\n",
      "One Day We'll All Be Dead and None of This Will Matter\n",
      "Since We Fell\n",
      "The Wolf Gift\n"
     ]
    }
   ],
   "source": [
    "recommended_books = top_n_recommendations_item_based\n",
    "\n",
    "for book_id in recommended_books:\n",
    "    work_id = get_work_id(book_id)\n",
    "    title = get_original_title_by_book_id(work_id, book_works_df)\n",
    "    if title == None or title == \"nan\" :\n",
    "        continue\n",
    "    print(title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
